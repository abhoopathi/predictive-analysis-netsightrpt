{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# App Response time per application per source (P1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we testing the different models for the p1 report with latest architecture (aggregated data to one day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql import SQLContext\n",
    "import sys\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import pymysql\n",
    "from tqdm import tqdm\n",
    "import config\n",
    "\n",
    "# initialise sparkContext\n",
    "spark1 = SparkSession.builder \\\n",
    "        .master(config.sp_master) \\\n",
    "        .appName(config.sp_appname) \\\n",
    "        .config('spark.executor.memory', config.sp_memory) \\\n",
    "        .config(\"spark.cores.max\", config.sp_cores) \\\n",
    "        .getOrCreate()\n",
    "    \n",
    "sc = spark1.sparkContext\n",
    "\n",
    "# using SQLContext to read parquet file\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sqlContext.read.parquet('./../datas/appid_datapoint_parquet1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap_list = ['DNS', 'DHCP', 'Radius', 'LDAP','Kerberos']\n",
    "s_list  = ['10.6.1.101','134.141.5.104']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prophet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pymysql\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from datetime import datetime, timedelta\n",
    "import logging\n",
    "from joblib import Parallel, delayed\n",
    "from fbprophet import Prophet\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "import math\n",
    "\n",
    "\n",
    "def connect_to_mysql():\n",
    "    connection = pymysql.connect(host = config.db_host,\n",
    "                            port= config.db_port,\n",
    "                            user= config.db_user,\n",
    "                            password= config.db_pass,\n",
    "                            db= config.db_name,\n",
    "                            charset='utf8',\n",
    "                            cursorclass=pymysql.cursors.DictCursor)\n",
    "    return connection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prophet model train and forecast funtion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prophet_m(app_name,z1,delay=24):\n",
    "    \n",
    "    ### --- For realtime pred ---###\n",
    "    \n",
    "    full_df = z1.app_rsp_time.iloc[0:len(z1)]\n",
    "    full_df = full_df.reset_index()\n",
    "    full_df.columns = ['ds','y']\n",
    "    \n",
    "    #removing outliers\n",
    "    q50 = full_df.y.median()\n",
    "    q100 = full_df.y.quantile(1)\n",
    "    q75  = full_df.y.quantile(.75)\n",
    "    \n",
    "    #if((q100-q50) >= (2*q75)):\n",
    "        \n",
    "    #    full_df.loc[full_df.y>=(2*q75),'y'] = None\n",
    "    \n",
    "    if(len(full_df.dropna())>=10):\n",
    "        \n",
    "        #-- Realtime prediction --##\n",
    "        #model \n",
    "        model_r = Prophet(yearly_seasonality=False,changepoint_prior_scale=.1,seasonality_prior_scale=0.05)\n",
    "        model_r.fit(full_df)\n",
    "        future_r = model_r.make_future_dataframe(periods=delay,freq='D')\n",
    "        forecast_r = model_r.predict(future_r)\n",
    "        forecast_r.index = forecast_r['ds']\n",
    "        #forecast \n",
    "        pred_r = pd.DataFrame(forecast_r['yhat'][len(z1):(len(z1)+delay)])\n",
    "        pred_r=pred_r.reset_index()\n",
    "        #--- completes realtime pred ---#\n",
    "\n",
    "    #----- validation ----#    \n",
    "    train_end_index=len(z1.app_rsp_time)-delay\n",
    "    train_df=z1.app_rsp_time.iloc[0:train_end_index]\n",
    "    \n",
    "    test_df=z1.app_rsp_time.iloc[train_end_index:len(z1)]\n",
    "    \n",
    "    train_df=train_df.reset_index()\n",
    "    test_df=test_df.reset_index()\n",
    "    train_df.columns=['ds','y']\n",
    "    \n",
    "    #--- removing outliers in trainset  ---#\n",
    "    \n",
    "    q50 = train_df.y.median()\n",
    "    q100 = train_df.y.quantile(1)\n",
    "    q75  = train_df.y.quantile(.75)\n",
    "    \n",
    "    if((q100-q50) >= (2*q75)):\n",
    "        \n",
    "        train_df.loc[train_df.y>=(2*q75),'y'] = None\n",
    "        \n",
    "    if(len(train_df.dropna())>=10):\n",
    "    \n",
    "        test_df.columns=['ds','y']\n",
    "        test_df['ds'] = pd.to_datetime(test_df['ds'])\n",
    "        \n",
    "        #model \n",
    "        model = Prophet(yearly_seasonality=False,changepoint_prior_scale=.1,seasonality_prior_scale=0.05)\n",
    "        model.fit(train_df)\n",
    "    \n",
    "        future = model.make_future_dataframe(periods=len(test_df),freq='D')\n",
    "        forecast = model.predict(future)\n",
    "        forecast.index = forecast['ds']\n",
    "        #forecast \n",
    "        pred = pd.DataFrame(forecast['yhat'][train_end_index:len(z1)])\n",
    "        pred=pred.reset_index()\n",
    "        pred_df=pd.merge(test_df,pred,on='ds',how='left')\n",
    "        pred_df.dropna(inplace=True)\n",
    "        \n",
    "        df=pd.DataFrame()\n",
    "    \n",
    "    \n",
    "        \n",
    "        if(len(pred_df)>0):\n",
    "            \n",
    "            pred_df['error_test']=pred_df.y-pred_df.yhat\n",
    "        \n",
    "            \n",
    "        \n",
    "            MSE=mse(pred_df.y,pred_df.yhat)\n",
    "            RMSE=math.sqrt(MSE)\n",
    "            pred_df['APE']=abs(pred_df.error_test*100/pred_df.y)\n",
    "            MAPE=pred_df.APE.mean()\n",
    "            min_error_rate = pred_df['APE'].quantile(0)/100\n",
    "            max_error_rate = pred_df['APE'].quantile(1)/100\n",
    "            median_error_rate = pred_df['APE'].quantile(.50)/100\n",
    "            print(\"App name:\",app_name)\n",
    "            #print(\"MSE  :\",MSE)\n",
    "            print(\"RMSE :\",RMSE)\n",
    "            print(\"MAPE :\",MAPE)\n",
    "            \n",
    "           \n",
    "            mape_q98=pred_df['APE'][pred_df.APE<pred_df['APE'].quantile(0.98)].mean()\n",
    "            std_MAPE = math.sqrt(((pred_df.APE-MAPE)**2).mean())\n",
    "    \n",
    "            df = pd.DataFrame({'length':len(z1),\n",
    "                                 'test_rmse':RMSE,\n",
    "                                 'test_mape':MAPE,\n",
    "                                 'std_mape':std_MAPE, #standerd deviation of mape\n",
    "                                 'min_error_rate':min_error_rate ,\n",
    "                                 'max_error_rate':max_error_rate ,\n",
    "                                 'median_error_rate':median_error_rate,\n",
    "                     \n",
    "                     'test_mape_98':mape_q98},\n",
    "                       \n",
    "                              index=[app_name])\n",
    "\n",
    "    return(df,model,forecast,pred_df,pred_r)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to select a combination , data preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- Function to select a combination for the run\n",
    "\n",
    "def forcomb(s,a,df,ftime1):\n",
    "    \n",
    "    df2 = df[ (df.source == s)]\n",
    "   \n",
    "    prophet_df = pd.DataFrame()\n",
    "    prophet_analysis_df = pd.DataFrame()\n",
    "    prophet_future_df = pd.DataFrame()\n",
    "\n",
    "    df2['date'] = df2.index.date\n",
    "    \n",
    "    df2 = pd.DataFrame(df2.groupby(by='date').app_rsp_time.max())\n",
    "    \n",
    "    df2 = df2.reset_index()\n",
    "    df2 = df2.sort_values(by='date',ascending=True)\n",
    "    df2.index = df2['date']\n",
    "    del df2['date']\n",
    "    df2['application'] = df.application[0]\n",
    "    df2['source'] = s\n",
    "\n",
    "    print('length of data = ',len(df2))\n",
    "   \n",
    "    if(len(df2)>config.limit):\n",
    "             \n",
    "        prophet_analysis_df,ew_model,ew_forcast,prophet_df,prophet_future_df =(create_prophet_m(a,df2,config.delay))\n",
    "\n",
    "\n",
    "        \n",
    "        t2 = datetime.now()\n",
    "        prophet_analysis_df['total_run_time'] = round(((t2-ftime1).seconds/60),2)\n",
    "        \n",
    "        prophet_analysis_df['application'] = a\n",
    "        prophet_analysis_df['source'] = s\n",
    "        \n",
    "            \n",
    "       \n",
    "        prophet_future_df['application'] = a\n",
    "        prophet_future_df['source'] = s\n",
    "        \n",
    "        prophet_df['application'] = a\n",
    "        prophet_df['source'] = s\n",
    "\n",
    "    df2 = df2.reset_index()\n",
    "    return prophet_df, prophet_analysis_df, prophet_future_df , df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running for selected application-source model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]/opt/conda/lib/python3.6/site-packages/pyspark/sql/dataframe.py:138: DeprecationWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  \"Deprecated in 2.0, use createOrReplaceTempView instead.\", DeprecationWarning)\n",
      "INFO:fbprophet.forecaster:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of data =  83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fbprophet.forecaster:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "App name: DNS\n",
      "RMSE : 14347.067542219651\n",
      "MAPE : 9.901297640116233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fbprophet.forecaster:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of data =  91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fbprophet.forecaster:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      " 20%|██        | 1/5 [00:49<03:16, 49.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "App name: DNS\n",
      "RMSE : 85111.15953214842\n",
      "MAPE : 167.16615366435727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fbprophet.forecaster:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of data =  83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fbprophet.forecaster:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "App name: DHCP\n",
      "RMSE : 4679.9612289951265\n",
      "MAPE : 19.7134602487719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fbprophet.forecaster:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of data =  91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fbprophet.forecaster:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      " 40%|████      | 2/5 [01:30<02:20, 46.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "App name: DHCP\n",
      "RMSE : 35847.27360488089\n",
      "MAPE : 213.04508412290983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fbprophet.forecaster:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of data =  83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fbprophet.forecaster:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "App name: Radius\n",
      "RMSE : 215411.14095414203\n",
      "MAPE : 218.31420463951537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fbprophet.forecaster:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of data =  91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fbprophet.forecaster:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      " 60%|██████    | 3/5 [02:11<01:29, 44.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "App name: Radius\n",
      "RMSE : 297551.9482378622\n",
      "MAPE : 453.1652536553806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fbprophet.forecaster:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of data =  83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fbprophet.forecaster:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "App name: LDAP\n",
      "RMSE : 17253.77914011522\n",
      "MAPE : 19.04315799056373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fbprophet.forecaster:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of data =  91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fbprophet.forecaster:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      " 80%|████████  | 4/5 [02:51<00:43, 43.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "App name: LDAP\n",
      "RMSE : 3542.2710131865615\n",
      "MAPE : 16.693479647987633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fbprophet.forecaster:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of data =  83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fbprophet.forecaster:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "App name: Kerberos\n",
      "RMSE : 31921.432920459934\n",
      "MAPE : 21.67788254492486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fbprophet.forecaster:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of data =  91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fbprophet.forecaster:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "100%|██████████| 5/5 [03:32<00:00, 42.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "App name: Kerberos\n",
      "RMSE : 47893.9651024127\n",
      "MAPE : 82.13305389834194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "a = ap_list[0]\n",
    "s = s_list[0]\n",
    "prophet_analysis_df_full = pd.DataFrame()\n",
    "\n",
    "for a in tqdm(ap_list):\n",
    "    for s in s_list:\n",
    "        qt1 = datetime.now()\n",
    "        data = df[(df.application == a ) & (df.source==s)]\n",
    "\n",
    "        df_t = data.registerTempTable('dummy')\n",
    "        df_t = sqlContext.sql('select avg(app_rsp_time) as app_rsp_time, time_stamp, source , application  from dummy group by source, application, time_stamp')\n",
    "       \n",
    "        # data cleaning\n",
    "        df_t = df_t[df_t.app_rsp_time!=0]\n",
    "        app_rsp_time_df=df_t.toPandas()\n",
    "    \n",
    "\n",
    "        #s_array = app_rsp_time_df.source.unique()\n",
    "\n",
    "        app_rsp_time_df = app_rsp_time_df.sort_values(by='app_rsp_time',ascending=True)       \n",
    "        dates_outlook = pd.to_datetime(pd.Series(app_rsp_time_df.time_stamp),unit='ms')\n",
    "        app_rsp_time_df.index = dates_outlook   \n",
    "        app_rsp_time_df = app_rsp_time_df.sort_values(by='time_stamp')\n",
    "        prophet_df,prophet_analysis_df,prophet_future_df,app_rsp_time_full_df = forcomb(s,a,app_rsp_time_df,qt1)\n",
    "\n",
    "        prophet_analysis_df_full = prophet_analysis_df_full.append(prophet_analysis_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>test_mape</th>\n",
       "      <th>std_mape</th>\n",
       "      <th>min_error_rate</th>\n",
       "      <th>max_error_rate</th>\n",
       "      <th>median_error_rate</th>\n",
       "      <th>test_mape_98</th>\n",
       "      <th>total_run_time</th>\n",
       "      <th>application</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DNS</th>\n",
       "      <td>83</td>\n",
       "      <td>14347.067542</td>\n",
       "      <td>9.901298</td>\n",
       "      <td>13.901434</td>\n",
       "      <td>0.001385</td>\n",
       "      <td>0.543710</td>\n",
       "      <td>0.047777</td>\n",
       "      <td>8.122511</td>\n",
       "      <td>0.42</td>\n",
       "      <td>DNS</td>\n",
       "      <td>10.6.1.101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DNS</th>\n",
       "      <td>91</td>\n",
       "      <td>85111.159532</td>\n",
       "      <td>167.166154</td>\n",
       "      <td>251.379000</td>\n",
       "      <td>0.545330</td>\n",
       "      <td>15.012395</td>\n",
       "      <td>1.094283</td>\n",
       "      <td>121.163624</td>\n",
       "      <td>0.38</td>\n",
       "      <td>DNS</td>\n",
       "      <td>134.141.5.104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DHCP</th>\n",
       "      <td>83</td>\n",
       "      <td>4679.961229</td>\n",
       "      <td>19.713460</td>\n",
       "      <td>14.130677</td>\n",
       "      <td>0.004188</td>\n",
       "      <td>0.521598</td>\n",
       "      <td>0.171683</td>\n",
       "      <td>18.415608</td>\n",
       "      <td>0.33</td>\n",
       "      <td>DHCP</td>\n",
       "      <td>10.6.1.101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DHCP</th>\n",
       "      <td>91</td>\n",
       "      <td>35847.273605</td>\n",
       "      <td>213.045084</td>\n",
       "      <td>319.413125</td>\n",
       "      <td>0.143294</td>\n",
       "      <td>18.019294</td>\n",
       "      <td>1.133730</td>\n",
       "      <td>158.255971</td>\n",
       "      <td>0.35</td>\n",
       "      <td>DHCP</td>\n",
       "      <td>134.141.5.104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Radius</th>\n",
       "      <td>83</td>\n",
       "      <td>215411.140954</td>\n",
       "      <td>218.314205</td>\n",
       "      <td>255.396785</td>\n",
       "      <td>0.018991</td>\n",
       "      <td>8.441537</td>\n",
       "      <td>0.811838</td>\n",
       "      <td>193.280626</td>\n",
       "      <td>0.32</td>\n",
       "      <td>Radius</td>\n",
       "      <td>10.6.1.101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Radius</th>\n",
       "      <td>91</td>\n",
       "      <td>297551.948238</td>\n",
       "      <td>453.165254</td>\n",
       "      <td>601.961855</td>\n",
       "      <td>0.007443</td>\n",
       "      <td>20.482787</td>\n",
       "      <td>1.646370</td>\n",
       "      <td>398.161342</td>\n",
       "      <td>0.33</td>\n",
       "      <td>Radius</td>\n",
       "      <td>134.141.5.104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LDAP</th>\n",
       "      <td>83</td>\n",
       "      <td>17253.779140</td>\n",
       "      <td>19.043158</td>\n",
       "      <td>12.934330</td>\n",
       "      <td>0.010976</td>\n",
       "      <td>0.571972</td>\n",
       "      <td>0.153255</td>\n",
       "      <td>17.516996</td>\n",
       "      <td>0.33</td>\n",
       "      <td>LDAP</td>\n",
       "      <td>10.6.1.101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LDAP</th>\n",
       "      <td>91</td>\n",
       "      <td>3542.271013</td>\n",
       "      <td>16.693480</td>\n",
       "      <td>30.160869</td>\n",
       "      <td>0.004622</td>\n",
       "      <td>1.764835</td>\n",
       "      <td>0.115175</td>\n",
       "      <td>11.183479</td>\n",
       "      <td>0.33</td>\n",
       "      <td>LDAP</td>\n",
       "      <td>134.141.5.104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kerberos</th>\n",
       "      <td>83</td>\n",
       "      <td>31921.432920</td>\n",
       "      <td>21.677883</td>\n",
       "      <td>15.451168</td>\n",
       "      <td>0.007299</td>\n",
       "      <td>0.501217</td>\n",
       "      <td>0.151835</td>\n",
       "      <td>20.540130</td>\n",
       "      <td>0.33</td>\n",
       "      <td>Kerberos</td>\n",
       "      <td>10.6.1.101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kerberos</th>\n",
       "      <td>91</td>\n",
       "      <td>47893.965102</td>\n",
       "      <td>82.133054</td>\n",
       "      <td>42.150376</td>\n",
       "      <td>0.263044</td>\n",
       "      <td>2.754134</td>\n",
       "      <td>0.811270</td>\n",
       "      <td>75.468215</td>\n",
       "      <td>0.33</td>\n",
       "      <td>Kerberos</td>\n",
       "      <td>134.141.5.104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          length      test_rmse   test_mape    std_mape  min_error_rate  \\\n",
       "DNS           83   14347.067542    9.901298   13.901434        0.001385   \n",
       "DNS           91   85111.159532  167.166154  251.379000        0.545330   \n",
       "DHCP          83    4679.961229   19.713460   14.130677        0.004188   \n",
       "DHCP          91   35847.273605  213.045084  319.413125        0.143294   \n",
       "Radius        83  215411.140954  218.314205  255.396785        0.018991   \n",
       "Radius        91  297551.948238  453.165254  601.961855        0.007443   \n",
       "LDAP          83   17253.779140   19.043158   12.934330        0.010976   \n",
       "LDAP          91    3542.271013   16.693480   30.160869        0.004622   \n",
       "Kerberos      83   31921.432920   21.677883   15.451168        0.007299   \n",
       "Kerberos      91   47893.965102   82.133054   42.150376        0.263044   \n",
       "\n",
       "          max_error_rate  median_error_rate  test_mape_98  total_run_time  \\\n",
       "DNS             0.543710           0.047777      8.122511            0.42   \n",
       "DNS            15.012395           1.094283    121.163624            0.38   \n",
       "DHCP            0.521598           0.171683     18.415608            0.33   \n",
       "DHCP           18.019294           1.133730    158.255971            0.35   \n",
       "Radius          8.441537           0.811838    193.280626            0.32   \n",
       "Radius         20.482787           1.646370    398.161342            0.33   \n",
       "LDAP            0.571972           0.153255     17.516996            0.33   \n",
       "LDAP            1.764835           0.115175     11.183479            0.33   \n",
       "Kerberos        0.501217           0.151835     20.540130            0.33   \n",
       "Kerberos        2.754134           0.811270     75.468215            0.33   \n",
       "\n",
       "         application         source  \n",
       "DNS              DNS     10.6.1.101  \n",
       "DNS              DNS  134.141.5.104  \n",
       "DHCP            DHCP     10.6.1.101  \n",
       "DHCP            DHCP  134.141.5.104  \n",
       "Radius        Radius     10.6.1.101  \n",
       "Radius        Radius  134.141.5.104  \n",
       "LDAP            LDAP     10.6.1.101  \n",
       "LDAP            LDAP  134.141.5.104  \n",
       "Kerberos    Kerberos     10.6.1.101  \n",
       "Kerberos    Kerberos  134.141.5.104  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prophet_analysis_df_full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost is an implementation of gradient boosted decision trees designed for speed and performance that is dominative competitive machine learning.\n",
    "\n",
    "delay_pred function is used to make history date with specified delay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delay_pred(dataset,delay):\n",
    "    dataset2 = dataset.copy()\n",
    "    colnames = (dataset.columns)\n",
    "    for i in range((delay),len(dataset)):\n",
    "        \n",
    "        for j in range(0,len(colnames)):\n",
    "            colmn1 = colnames[j]\n",
    "            if(colmn1 in ['app_rsp_time','hour','weekday','app_rsp_time_t-1']):\n",
    "                continue\n",
    "            dataset2[colmn1][i] = dataset.iloc[(i-delay):i,j].mean()\n",
    "            #dataset2.set_values(i,colmn1, dataset2.iloc[i:(i+delay),j].mean())\n",
    "    \n",
    "    return dataset2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "forcast_shifter funtion is used to shift the output(app_rsp_time) as per the point to be predicted using the history data , and also it adjust the length of given x & y data after the shifting operation to avoid the na values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forcast_shifter(X,y,forcast_lag):\n",
    "    \n",
    "    y1=y.shift(-forcast_lag)\n",
    "    X1=X.iloc[0:X.shape[0]-forcast_lag,:].astype('float64')\n",
    "    y1 = y1[0:len(y1)-forcast_lag]\n",
    "    return X1,y1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGB prediction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  xgb_all_real_24(data_l_ew_g,history_lag=5,forcast_lag=1):\n",
    "    import numpy as np\n",
    "    \n",
    "    data_l_ew_g1 = data_l_ew_g.copy()\n",
    "    data_l_ew_history = delay_pred(data_l_ew_g1,history_lag)\n",
    "    # Removing the outlier\n",
    "    #data_l_ew_history.loc[data_l_ew_history['app_rsp_time']==max(data_l_ew_history['app_rsp_time']),'app_rsp_time']= data_l_ew_history['app_rsp_time'].quantile(.9)*.2\n",
    "\n",
    "    ###### Removing the outlier ######\n",
    "    #cutter = data_l_ew_history['app_rsp_time'].quantile(.90)\n",
    "    #data_l_ew_history.loc[data_l_ew_history['app_rsp_time']> cutter,'app_rsp_time']= cutter\n",
    "    #data_l_ew_history['app_rsp_time'] = (data_l_ew_history['app_rsp_time'])\n",
    "    \n",
    "    import random\n",
    "    import datetime\n",
    "    \n",
    "    random.seed(100)\n",
    "    data_l_ew_history['date'] = data_l_ew_history.index\n",
    "    data_l_ew_history=data_l_ew_history.sort_values(by='date')\n",
    "    from pandas.tseries.holiday import USFederalHolidayCalendar as calendar\n",
    "    cal = calendar()\n",
    "    holidays = cal.holidays(start = data_l_ew_history.date.min(), end = data_l_ew_history.date.max())\n",
    "    #data_l_ew_history[\"IS_HOLIDAY\"] = data_l_ew_history.date.isin(holidays)\n",
    "    #data_l_ew_history[\"IS_WORKDAY\"] = data_l_ew_history.date.apply(lambda x: 0 if x.dayofweek > 5 else 1  )\n",
    "    import xgboost as xgb\n",
    "    from sklearn.cross_validation import train_test_split as ttsplit\n",
    "    from sklearn.datasets import load_boston\n",
    "    from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "    #--- Model without is_workday and is_holiday ---#\n",
    "    import numpy as np\n",
    "    #X = pd.concat([data_l_ew_history.iloc[:,0:13],data_l_ew_history.iloc[:,14:16]],axis=1).values\n",
    "    X = data_l_ew_history.iloc[0:len(data_l_ew_history),1:data_l_ew_history.shape[1]-1].values\n",
    "    y = np.array((data_l_ew_history['app_rsp_time']))\n",
    "    predicted1 =list()\n",
    "    split2 = int(len(X)-forcast_lag)\n",
    "    \n",
    "    X_test_t = X[split2:len(X),:]\n",
    "    \n",
    "    y_test_t = y[split2:len(y)]\n",
    "    k=24\n",
    "    \n",
    "    \n",
    "    for j in range(0,forcast_lag):\n",
    "        \n",
    "        #--- Shifting as per required forcast ------\n",
    "        X1,y1 = forcast_shifter(data_l_ew_history.iloc[0:len(data_l_ew_history),1:data_l_ew_history.shape[1]-1],\n",
    "                                data_l_ew_history['app_rsp_time'],j)\n",
    "        X = X1.values\n",
    "        y = np.array(np.log(y1))\n",
    "        #y = np.array(y1)\n",
    "        #y_train,y_test = forcast_shifter\n",
    "        # split data into training and testing sets\n",
    "        # then split training set in half\n",
    "        #X_train, X_test, y_train, y_test = ttsplit(X, y, test_size=0.3, random_state=0)\n",
    "        #split2 = int(len(X)*.7)\n",
    "        # lenght of data frame X will reduce when j shift is done \n",
    "        #split2 = int(len(X)-(24-j))\n",
    "        X_train = X[0:split2,:]\n",
    "        X_test = X[split2:len(X),:]\n",
    "        y_train = y[0:split2]\n",
    "        y_test = y[split2:len(X)]\n",
    "        xg_train_1 = xgb.DMatrix(X_train, label=y_train)\n",
    "        #xg_train_2 = xgb.DMatrix(X_train_2, label=y_train_2)\n",
    "        xg_test = xgb.DMatrix(X_test, label=y_test)\n",
    "    \n",
    "        s_time = datetime.datetime.now()\n",
    "\n",
    "        params = {'objective': 'reg:linear', 'verbose': True , 'eval' : 'rmse ' ,'gamma':.01,\n",
    "                 'max_depth':3, 'min_child_weight':3,'eta':.02,'num_round':350}\n",
    "        #params = {  'objective':'reg:linear' , 'verbose': True , 'eval' : 'rmse ' }\n",
    "        model_1_mean5 = xgb.train(params, xg_train_1, 200)\n",
    "        e_time = datetime.datetime.now()\n",
    "        run_time = (e_time - s_time)\n",
    "        #print((run_time.seconds)/60,\"minuts\")\n",
    "\n",
    "        #--- Training and testing rmse finding ---#\n",
    "    \n",
    "    \n",
    "        ### Test set manipulations ###\n",
    "        predicted_dummy = model_1_mean5.predict(xg_test)\n",
    "        predicted1.append(predicted_dummy[0])\n",
    "        \n",
    "    \n",
    "    y_test = (y_test_t)\n",
    "    predicted1 = np.exp(predicted1)\n",
    "    \n",
    "    delta = pd.Series(( y_test - predicted1))\n",
    "    compar_test = pd.DataFrame({'predicted':predicted1,'actual':y_test,'error':delta})\n",
    "    compar_test['perc_error']= abs(compar_test['error']/compar_test['actual']*100)\n",
    "   # xgb_mse_test =(mse(compar_test['predicted'] , compar_test['actual']))\n",
    "   # xgb_rmse_test = math.sqrt(xgb_mse_test)\n",
    "\n",
    "    #print('test rmse',xgb_rmse_test )\n",
    "    \n",
    "    xgb_mape_test = compar_test.perc_error.mean()\n",
    "    print('MAPE = ',xgb_mape_test)\n",
    "    \n",
    "    q98=compar_test['perc_error'].quantile(0.98)\n",
    "    mape_q98_test =compar_test['perc_error'][compar_test.perc_error<compar_test['perc_error'].quantile(0.98)].mean()\n",
    "    print('MAPE clipped at 98% = ',mape_q98_test)\n",
    "    \n",
    "    mm ='xgboost_hist'+str(history_lag)+'_forcast_'+str(forcast_lag)\n",
    "    df = pd.DataFrame({'Model':[mm],#'predicted_t':[forcast_lag],\n",
    "                         \n",
    "                         #'test_rmse':[round(xgb_rmse_test,2)],\n",
    "                         \n",
    "                         'test_mape':[round(xgb_mape_test,2)],\n",
    "                       \n",
    "                       'test_mape_98':[round(mape_q98_test,2)]\n",
    "                      })\n",
    "    return df,compar_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running xgboost model for selected application-source model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]/opt/conda/lib/python3.6/site-packages/pyspark/sql/dataframe.py:138: DeprecationWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  \"Deprecated in 2.0, use createOrReplaceTempView instead.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE =  15.357276559248477\n",
      "MAPE clipped at 98% =  13.703076390449397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/pyspark/sql/dataframe.py:138: DeprecationWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  \"Deprecated in 2.0, use createOrReplaceTempView instead.\", DeprecationWarning)\n",
      " 20%|██        | 1/5 [02:22<09:30, 142.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE =  38.1075791974915\n",
      "MAPE clipped at 98% =  36.08515673663361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/pyspark/sql/dataframe.py:138: DeprecationWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  \"Deprecated in 2.0, use createOrReplaceTempView instead.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE =  22.35452386208162\n",
      "MAPE clipped at 98% =  21.01546122901599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/pyspark/sql/dataframe.py:138: DeprecationWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  \"Deprecated in 2.0, use createOrReplaceTempView instead.\", DeprecationWarning)\n",
      " 40%|████      | 2/5 [04:35<06:58, 139.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE =  84.55030433720329\n",
      "MAPE clipped at 98% =  63.80971854554812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/pyspark/sql/dataframe.py:138: DeprecationWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  \"Deprecated in 2.0, use createOrReplaceTempView instead.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE =  134.86000919749847\n",
      "MAPE clipped at 98% =  111.73174716791196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/pyspark/sql/dataframe.py:138: DeprecationWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  \"Deprecated in 2.0, use createOrReplaceTempView instead.\", DeprecationWarning)\n",
      " 60%|██████    | 3/5 [06:45<04:33, 136.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE =  115.07664168604329\n",
      "MAPE clipped at 98% =  100.54085225753579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/pyspark/sql/dataframe.py:138: DeprecationWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  \"Deprecated in 2.0, use createOrReplaceTempView instead.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE =  29.603663474747755\n",
      "MAPE clipped at 98% =  28.823413572087784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/pyspark/sql/dataframe.py:138: DeprecationWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  \"Deprecated in 2.0, use createOrReplaceTempView instead.\", DeprecationWarning)\n",
      " 80%|████████  | 4/5 [09:02<02:16, 136.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE =  22.08486728786885\n",
      "MAPE clipped at 98% =  20.85175220391168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/pyspark/sql/dataframe.py:138: DeprecationWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  \"Deprecated in 2.0, use createOrReplaceTempView instead.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE =  29.469273586968182\n",
      "MAPE clipped at 98% =  28.733809630656587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/pyspark/sql/dataframe.py:138: DeprecationWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  \"Deprecated in 2.0, use createOrReplaceTempView instead.\", DeprecationWarning)\n",
      "100%|██████████| 5/5 [11:08<00:00, 133.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE =  29.978556663788773\n",
      "MAPE clipped at 98% =  28.208025047453376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "a = ap_list[0]\n",
    "s = s_list[0]\n",
    "xgb_analysis_df_full = pd.DataFrame()\n",
    "\n",
    "for a in tqdm(ap_list):\n",
    "    for s in s_list:\n",
    "        qt1 = datetime.now()\n",
    "        data = df[(df.application == a ) & (df.source==s)]\n",
    "\n",
    "        df_t = data.registerTempTable('dummy')\n",
    "        df_t = sqlContext.sql('select avg(app_rsp_time) as app_rsp_time, time_stamp, avg(byte_count)  as byte_count, avg(flow_count) as flow_count , avg(rx_byte_count) as rx_byte_count , avg(rx_flow_count) as rx_flow_count , avg(tcp_rsp_time) as tcp_rsp_time , avg(tx_byte_count) as tx_byte_count , avg(tx_flow_count) as tx_flow_count from dummy group by source, application, time_stamp')\n",
    "\n",
    "\n",
    "        # data cleaning\n",
    "        df_t = df_t[df_t.app_rsp_time!=0]\n",
    "        app_rsp_time_df=df_t.toPandas() \n",
    "\n",
    "   \n",
    "        app_rsp_time_df = app_rsp_time_df.sort_values(by='app_rsp_time',ascending=True)       \n",
    "        dates_outlook = pd.to_datetime(pd.Series(app_rsp_time_df.time_stamp),unit='ms')\n",
    "        app_rsp_time_df.index = dates_outlook   \n",
    "        app_rsp_time_df = app_rsp_time_df.sort_values(by='time_stamp')\n",
    "\n",
    "        app_rsp_time_df['date'] = app_rsp_time_df.index.date\n",
    "        del app_rsp_time_df['time_stamp']\n",
    "\n",
    "        app_rsp_time_df = app_rsp_time_df.reset_index()\n",
    "        weekday = app_rsp_time_df.time_stamp.dt.weekday\n",
    "        app_rsp_time_df['weekday'] = weekday\n",
    "        del app_rsp_time_df['time_stamp']\n",
    "\n",
    "        app_rsp_time_df = pd.DataFrame(app_rsp_time_df.groupby(by='date')['app_rsp_time','byte_count','flow_count','rx_byte_count','rx_flow_count', 'tcp_rsp_time', 'tx_byte_count', 'tx_flow_count','weekday'].max())\n",
    "\n",
    "        analyse_df,compare_test=xgb_all_real_24(app_rsp_time_df,5,30)\n",
    "        xgb_analysis_df_full = xgb_analysis_df_full.append(analyse_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>test_mape</th>\n",
       "      <th>test_mape_98</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xgboost_hist5_forcast_30</td>\n",
       "      <td>15.36</td>\n",
       "      <td>13.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xgboost_hist5_forcast_30</td>\n",
       "      <td>38.11</td>\n",
       "      <td>36.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xgboost_hist5_forcast_30</td>\n",
       "      <td>22.35</td>\n",
       "      <td>21.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xgboost_hist5_forcast_30</td>\n",
       "      <td>84.55</td>\n",
       "      <td>63.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xgboost_hist5_forcast_30</td>\n",
       "      <td>134.86</td>\n",
       "      <td>111.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xgboost_hist5_forcast_30</td>\n",
       "      <td>115.08</td>\n",
       "      <td>100.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xgboost_hist5_forcast_30</td>\n",
       "      <td>29.60</td>\n",
       "      <td>28.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xgboost_hist5_forcast_30</td>\n",
       "      <td>22.08</td>\n",
       "      <td>20.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xgboost_hist5_forcast_30</td>\n",
       "      <td>29.47</td>\n",
       "      <td>28.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xgboost_hist5_forcast_30</td>\n",
       "      <td>29.98</td>\n",
       "      <td>28.21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model  test_mape  test_mape_98\n",
       "0  xgboost_hist5_forcast_30      15.36         13.70\n",
       "0  xgboost_hist5_forcast_30      38.11         36.09\n",
       "0  xgboost_hist5_forcast_30      22.35         21.02\n",
       "0  xgboost_hist5_forcast_30      84.55         63.81\n",
       "0  xgboost_hist5_forcast_30     134.86        111.73\n",
       "0  xgboost_hist5_forcast_30     115.08        100.54\n",
       "0  xgboost_hist5_forcast_30      29.60         28.82\n",
       "0  xgboost_hist5_forcast_30      22.08         20.85\n",
       "0  xgboost_hist5_forcast_30      29.47         28.73\n",
       "0  xgboost_hist5_forcast_30      29.98         28.21"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_analysis_df_full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.embeddings  import  Embedding\n",
    "from keras.layers import LSTM,Dropout\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "from keras.callbacks import TensorBoard\n",
    "from time import time\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_shifter(y,forcast_lag):\n",
    "    \n",
    "    y1=y.shift(-forcast_lag)    \n",
    "    y1 = y1[0:len(y1)-forcast_lag]\n",
    "    return y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow import set_random_seed\n",
    "\n",
    "\n",
    "def lstm_new(data_l_ew_g_lstm,lag):\n",
    "    \n",
    "    \n",
    "    #data_l_ew_g_lstm = data_l_ew_g_lstm.iloc[:,0:13].copy()\n",
    "    data_l_ew_g_lstm1 = data_l_ew_g_lstm.copy()\n",
    "    cols = data_l_ew_g_lstm.columns\n",
    "    \n",
    "    ###### Removing the outlier ######\n",
    "    #cutter = data_l_ew_g_lstm['app_rsp_time'].quantile(.90)\n",
    "    #data_l_ew_g_lstm.loc[data_l_ew_g_lstm['app_rsp_time']> cutter,'app_rsp_time']= cutter\n",
    "    #data_l_ew_g_lstm['app_rsp_time'] = np.log(data_l_ew_g_lstm['app_rsp_time'])\n",
    "    \n",
    "    \n",
    "\n",
    "    # normalize the dataset\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    data_l_ew_g_lstm = pd.DataFrame(scaler.fit_transform(data_l_ew_g_lstm))\n",
    "\n",
    "\n",
    "    import numpy as np\n",
    "    #X_lstm = pd.concat([data_l_ew_history.iloc[:,1:13],data_l_ew_history.iloc[:,14:16]],axis=1)#.values\n",
    "    X_lstm = data_l_ew_g_lstm.iloc[:,1:len(cols)]\n",
    "    y_lstm_init = pd.DataFrame(data_l_ew_g_lstm.iloc[:,0])\n",
    "    \n",
    "    y_output = pd.DataFrame()\n",
    "    \n",
    "    for i in range(1,(lag+1)):\n",
    "        name_z='y'+str(i)\n",
    "        ff =lstm_shifter(y_lstm_init,i)\n",
    "        \n",
    "        #y_output[name_z]=list(ff.iloc[0:len(ff)-(lag-1-i),0])\n",
    "        y_output[name_z]=list(ff.iloc[0:len(X_lstm)-(lag),0])\n",
    "        \n",
    "    \n",
    "    y_lstm1= y_output.copy()\n",
    "    X_lstm1 = X_lstm.copy()\n",
    "\n",
    "    \n",
    "\n",
    "    split = int(len(y_lstm1)-(lag))\n",
    "    #train_x = X_lstm1.iloc[0:split-(lag-1),:].values\n",
    "    #test_x = X_lstm1.iloc[(split-lag):(split-1),:].values\n",
    "    \n",
    "    train_x = X_lstm1.iloc[0:split,:].values\n",
    "    test_x = X_lstm1.iloc[split:len(y_lstm1),:].values\n",
    "    \n",
    "\n",
    "    #train_y = y_lstm1.iloc[0:split-(lag-1),:].values\n",
    "    #test_y = y_lstm1.iloc[(split-lag):(split-1),:].values\n",
    "    train_y = y_lstm1.iloc[0:split,:].values\n",
    "    test_y = y_lstm1.iloc[split:len(y_lstm1),:].values\n",
    "\n",
    "    train_x = train_x.reshape(train_x.shape[0],1,train_x.shape[1])\n",
    "    test_x = test_x.reshape(test_x.shape[0],1,test_x.shape[1])\n",
    "\n",
    "    set_random_seed(7)    \n",
    "    model_m2=Sequential()\n",
    "    model_m2.add(LSTM(12, dropout=0.2,input_shape=(1,len(cols)-1),\n",
    "                  batch_input_shape=(1, train_x.shape[1], train_x.shape[2]), stateful=True))\n",
    "    model_m2.add(Dense(6, activation='relu'))\n",
    "    model_m2.add(Dropout(0.2))\n",
    "    model_m2.add(Dense(3, activation='relu'))\n",
    "    model_m2.add(Dropout(0.1))\n",
    "    model_m2.add(Dense(lag, activation='relu'))\n",
    "    model_m2.summary()\n",
    "    \n",
    "    model_m2.compile(optimizer='rmsprop',\n",
    "                  loss='mse')\n",
    "\n",
    "    r_lstm = model_m2.fit(train_x, train_y, epochs=10, batch_size=1,verbose=2 ,\n",
    "                          validation_data=(test_x,test_y) , shuffle=False)\n",
    "\n",
    "\n",
    "        \n",
    "    # make predictions\n",
    "    trainPredict = model_m2.predict(train_x,batch_size=1)\n",
    "    testPredict = model_m2.predict(test_x,batch_size=1)\n",
    "    \n",
    "     # Invert predictions\n",
    "    p_table0 = pd.concat( [pd.DataFrame(list(trainPredict[(len(trainPredict)-1)])).reset_index(drop=True),X_lstm.iloc[(split-lag):(split),0:13].reset_index(drop=True)],axis =1)\n",
    "    r_table0 = pd.concat( [pd.DataFrame(list(train_y[(len(train_y)-1)])).reset_index(drop=True),X_lstm.iloc[(split-lag):(split),0:13].reset_index(drop=True)],axis =1)\n",
    "\n",
    "    r_table1 = pd.DataFrame(scaler.inverse_transform(r_table0))\n",
    "    #r_table1 = r_table1.iloc[0:split,:]\n",
    "    p_table1 = pd.DataFrame(scaler.inverse_transform(p_table0))\n",
    "\n",
    "    tt1 = X_lstm.iloc[(split):(len(X_lstm)),0:len(cols)]\n",
    "    #tt1.set_index(tt.index)\n",
    "    tt1['app_rsp']=list(testPredict[(len(testPredict)-1)])\n",
    "    cols = tt1.columns.tolist()\n",
    "    cols = cols[-1:] + cols[:-1]\n",
    "    p_table_test0 = tt1[cols]\n",
    "    #p_table0 = p_table.dropna()\n",
    "    p_table_test0.head()\n",
    "\n",
    "    tt1 = X_lstm.iloc[(split):(len(X_lstm)),0:len(cols)]\n",
    "    #tt1.set_index(tt.index)\n",
    "    tt1['app_rsp']=list(test_y[(len(test_y)-1)])\n",
    "    cols = tt1.columns.tolist()\n",
    "    cols = cols[-1:] + cols[:-1]\n",
    "    r_table_test0 = tt1[cols]\n",
    "    #p_table0 = p_table.dropna()\n",
    "    r_table_test0.head()\n",
    "\n",
    "    # invert predictions\n",
    "    r_table_test = pd.DataFrame(scaler.inverse_transform(r_table_test0))\n",
    "    #r_table1 = r_table0.iloc[0:split,:]\n",
    "    p_table_test = pd.DataFrame(scaler.inverse_transform(p_table_test0))\n",
    "    \n",
    "    ### Train and test mape finding \n",
    "    \n",
    "    \n",
    "    compare_train  = pd.DataFrame({'train_real':r_table1.iloc[:,0],\n",
    "                                   'train_pred':p_table1.iloc[:,0]})\n",
    "    compare_train['error'] = abs(compare_train['train_real'] - compare_train['train_pred'])\n",
    "    compare_train['perc_error'] = compare_train['error']/compare_train['train_real']*100\n",
    "    lstm_mape_train = compare_train.perc_error.mean()\n",
    "    print('MAPE of train = ',lstm_mape_train)\n",
    "    lstm_rmse_train = math.sqrt(mean_squared_error(compare_train['train_real'], compare_train['train_pred']))\n",
    "    print(\"rmse of train = \",lstm_rmse_train)\n",
    "\n",
    "    compare_test  = pd.DataFrame({'test_real':r_table_test.iloc[:,0],\n",
    "                                   'test_pred':p_table_test.iloc[:,0]})\n",
    "    compare_test['error'] = abs(compare_test['test_real'] - compare_test['test_pred'])\n",
    "    compare_test['perc_error'] = compare_test['error']/compare_test['test_real']*100\n",
    "    lstm_mape_test = compare_test.perc_error.mean()\n",
    "    print('MAPE of test = ',lstm_mape_test)\n",
    "    lstm_rmse_test = math.sqrt(mean_squared_error(compare_test['test_real'], compare_test['test_pred']))\n",
    "    print(\"rmse of test = \",lstm_rmse_test)\n",
    "    \n",
    "    q98=compare_test['perc_error'].quantile(0.98)\n",
    "    mape_q98_test =compare_test['perc_error'][compare_test.perc_error<compare_test['perc_error'].quantile(0.98)].mean()\n",
    "    \n",
    "    \n",
    "    #mm ='lstm'\n",
    "    df = pd.DataFrame({#'Model':[mm],#'predicted_t':[forcast_lag],\n",
    "                        #'clipped_point':[round(clipped,2)],\n",
    "                         \n",
    "                         'train_rmse':[round(lstm_rmse_train,2)],\n",
    "                         'test_rmse':[round(lstm_rmse_test,2)],\n",
    "                         'train_mape':[round(lstm_mape_train,2)],\n",
    "                         'test_mape':[round(lstm_mape_test,2)],\n",
    "                       #'train_mape_98':[round(lstm_q98,2)],\n",
    "                       'test_mape_98':[round(mape_q98_test,2)]\n",
    "                      })\n",
    "    return df,compare_train,compare_test,r_lstm\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "def lstm_wt_new1(data_l_ew_g_lstm,lag):\n",
    "    \n",
    "    #take all input except date column\n",
    "    #data_l_ew_g_lstm = data_l_ew_g_lstm.iloc[:,0:13].copy()\n",
    "    data_l_ew_g_lstm1 = data_l_ew_g_lstm.copy()\n",
    "    cols = data_l_ew_g_lstm.columns\n",
    "    \n",
    "    ###### Removing the outlier ######\n",
    "    #cutter = data_l_ew_g_lstm['app_rsp_time'].quantile(.90)\n",
    "    #data_l_ew_g_lstm.loc[data_l_ew_g_lstm['app_rsp_time']> cutter,'app_rsp_time']= cutter\n",
    "    #data_l_ew_g_lstm['app_rsp_time'] = np.log(data_l_ew_g_lstm['app_rsp_time'])\n",
    "    \n",
    "    #filter all inputs except 'app_rsp_time','weekday','hour','byte_count'\n",
    "#    for c in data_l_ew_g_lstm.columns:\n",
    "#        if(c in ['app_rsp_time','weekday','hour','byte_count']):\n",
    "#            continue\n",
    "#        y1=deno_filter(data_l_ew_g_lstm[c])\n",
    "#        if(len(y1)!=len(data_l_ew_g_lstm)):\n",
    "#            y1 = deno_filter1(data_l_ew_g_lstm[c])\n",
    "#        data_l_ew_g_lstm[c]=y1\n",
    "\n",
    "    # normalize the dataset\n",
    "    #scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaler1=RobustScaler(quantile_range=(5,95))\n",
    "    scaler2=RobustScaler(quantile_range=(5,95))\n",
    "    #data_l_ew_g_lstm = pd.DataFrame(scaler.fit_transform(data_l_ew_g_lstm))\n",
    "\n",
    "\n",
    "    import numpy as np\n",
    "    #X_lstm = pd.concat([data_l_ew_history.iloc[:,1:13],data_l_ew_history.iloc[:,14:16]],axis=1)#.values\n",
    "    X_lstm = data_l_ew_g_lstm.iloc[:,1:len(cols)]\n",
    "    y_lstm_init = pd.DataFrame(data_l_ew_g_lstm.iloc[:,0])\n",
    "    \n",
    "    y_output = pd.DataFrame()\n",
    "    \n",
    "    for i in range(1,(lag+1)):\n",
    "        name_z='y'+str(i)\n",
    "        ff =lstm_shifter(y_lstm_init,i)\n",
    "        \n",
    "        #y_output[name_z]=list(ff.iloc[0:len(ff)-(lag-1-i),0])\n",
    "        y_output[name_z]=list(ff.iloc[0:len(X_lstm)-(lag),0])\n",
    "        \n",
    "    \n",
    "    y_lstm1= y_output.copy()\n",
    "    X_lstm1 = X_lstm.copy()\n",
    "\n",
    "    \n",
    "\n",
    "    split = int(len(y_lstm1)-(lag))\n",
    "    #train_x = X_lstm1.iloc[0:split-(lag-1),:].values\n",
    "    #test_x = X_lstm1.iloc[(split-lag):(split-1),:].values\n",
    "    \n",
    "    train_x = X_lstm1.iloc[0:split,:].values\n",
    "    test_x = X_lstm1.iloc[split:len(y_lstm1),:].values\n",
    "    \n",
    "\n",
    "    #train_y = y_lstm1.iloc[0:split-(lag-1),:].values\n",
    "    #test_y = y_lstm1.iloc[(split-lag):(split-1),:].values\n",
    "    train_y = y_lstm1.iloc[0:split,:].values\n",
    "    test_y = y_lstm1.iloc[split:len(y_lstm1),:].values\n",
    "    \n",
    "    # Normalisijng using robust scaler\n",
    "    scaler1 = scaler1.fit(train_x) \n",
    "    train_x = scaler1.transform(train_x)\n",
    "    test_x = scaler1.transform(test_x)\n",
    "    \n",
    "    scaler2 = scaler2.fit(train_y) \n",
    "    train_y = scaler2.transform(train_y)\n",
    "    test_y = scaler2.transform(test_y)\n",
    "\n",
    "    train_x = train_x.reshape(train_x.shape[0],1,train_x.shape[1])\n",
    "    test_x = test_x.reshape(test_x.shape[0],1,test_x.shape[1])\n",
    "\n",
    "    \n",
    "        \n",
    "    model_m2=Sequential()\n",
    "    model_m2.add(LSTM(12, dropout=0.2,input_shape=(1,len(cols)-1),\n",
    "                  batch_input_shape=(1, train_x.shape[1], train_x.shape[2]), stateful=True))\n",
    "    model_m2.add(Dense(8, activation='relu'))\n",
    "    model_m2.add(Dropout(0.2))\n",
    "    model_m2.add(Dense(6, activation='relu'))\n",
    "    model_m2.add(Dropout(0.1))\n",
    "    model_m2.add(Dense(lag, activation='relu'))\n",
    "    model_m2.summary()\n",
    "    \n",
    "    model_m2.compile(optimizer='rmsprop',\n",
    "                  loss='mse')\n",
    "    \n",
    "    \n",
    "\n",
    "    r_lstm = model_m2.fit(train_x, train_y, epochs=10, batch_size=1,verbose=2 ,\n",
    "                          validation_data=(test_x,test_y) , shuffle=False)\n",
    "\n",
    "    model_m2.reset_states()\n",
    "   \n",
    "    \n",
    "    # make predictions\n",
    "    trainPredict = model_m2.predict(train_x,batch_size=1)\n",
    "    testPredict = model_m2.predict(test_x,batch_size=1)\n",
    "        \n",
    "    \n",
    "    \n",
    "    # Invert predictions\n",
    "    \n",
    "    trainPredict1 = scaler2.inverse_transform(trainPredict)\n",
    "    testPredict1 = scaler2.inverse_transform(testPredict)\n",
    "    train_y1 = scaler2.inverse_transform(train_y)\n",
    "    test_y1 = scaler2.inverse_transform(test_y)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ### Train and test mape finding \n",
    "    \n",
    "    \n",
    "    compare_train  = pd.DataFrame({'actual':list(train_y1[(len(train_y1)-1)]),\n",
    "                                   'predicted':list(trainPredict1[(len(trainPredict1)-1)])})\n",
    "    compare_train['error'] = abs(compare_train['actual'] - compare_train['predicted'])\n",
    "    compare_train['perc_error'] = compare_train['error']/compare_train['actual']*100\n",
    "    lstm_mape_train = compare_train.perc_error.mean()\n",
    "    print('MAPE of train = ',lstm_mape_train)\n",
    "    lstm_rmse_train = math.sqrt(mean_squared_error(compare_train['actual'], compare_train['predicted']))\n",
    "    print(\"rmse of train = \",lstm_rmse_train)\n",
    "\n",
    "    compare_test  = pd.DataFrame({'actual':list(test_y1[(len(test_y1)-1)]),\n",
    "                                   'predicted':list(testPredict1[(len(testPredict1)-1)])})\n",
    "    compare_test['error'] = abs(compare_test['actual'] - compare_test['predicted'])\n",
    "    compare_test['perc_error'] = compare_test['error']/compare_test['actual']*100\n",
    "    lstm_mape_test = compare_test.perc_error.mean()\n",
    "    print('MAPE of test = ',lstm_mape_test)\n",
    "    lstm_rmse_test = math.sqrt(mean_squared_error(compare_test['actual'], compare_test['predicted']))\n",
    "    print(\"rmse of test = \",lstm_rmse_test)\n",
    "    \n",
    "    q98=compare_test['perc_error'].quantile(0.98)\n",
    "    mape_q98_test =compare_test['perc_error'][compare_test.perc_error<compare_test['perc_error'].quantile(0.98)].mean()\n",
    "    \n",
    "    \n",
    "    #mm ='lstm'\n",
    "    df = pd.DataFrame({#'Model':[mm],#'predicted_t':[forcast_lag],\n",
    "                        #'clipped_point':[round(clipped,2)],\n",
    "                         \n",
    "                         'train_rmse':[round(lstm_rmse_train,2)],\n",
    "                         'test_rmse':[round(lstm_rmse_test,2)],\n",
    "                         'train_mape':[round(lstm_mape_train,2)],\n",
    "                         'test_mape':[round(lstm_mape_test,2)],\n",
    "                       #'train_mape_98':[round(lstm_q98,2)],\n",
    "                       'test_mape_98':[round(mape_q98_test,2)]\n",
    "                      })\n",
    "    return df,compare_train,compare_test,r_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/pyspark/sql/dataframe.py:138: DeprecationWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  \"Deprecated in 2.0, use createOrReplaceTempView instead.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "data = df[(df.application == a ) & (df.source==s)]\n",
    "\n",
    "df_t = data.registerTempTable('dummy')\n",
    "df_t = sqlContext.sql('select avg(app_rsp_time) as app_rsp_time, time_stamp, avg(byte_count)  as byte_count, avg(flow_count) as flow_count , avg(rx_byte_count) as rx_byte_count , avg(rx_flow_count) as rx_flow_count , avg(tcp_rsp_time) as tcp_rsp_time , avg(tx_byte_count) as tx_byte_count , avg(tx_flow_count) as tx_flow_count from dummy group by source, application, time_stamp')\n",
    "\n",
    "\n",
    "# data cleaning\n",
    "df_t = df_t[df_t.app_rsp_time!=0]\n",
    "app_rsp_time_df=df_t.toPandas() \n",
    "\n",
    "   \n",
    "app_rsp_time_df = app_rsp_time_df.sort_values(by='app_rsp_time',ascending=True)\n",
    "dates_outlook = pd.to_datetime(pd.Series(app_rsp_time_df.time_stamp),unit='ms')\n",
    "app_rsp_time_df.index = dates_outlook   \n",
    "app_rsp_time_df = app_rsp_time_df.sort_values(by='time_stamp')\n",
    "\n",
    "app_rsp_time_df['date'] = app_rsp_time_df.index.date\n",
    "del app_rsp_time_df['time_stamp']\n",
    "\n",
    "app_rsp_time_df = app_rsp_time_df.reset_index()\n",
    "weekday = app_rsp_time_df.time_stamp.dt.weekday\n",
    "app_rsp_time_df['weekday'] = weekday\n",
    "del app_rsp_time_df['time_stamp']\n",
    "\n",
    "app_rsp_time_df = pd.DataFrame(app_rsp_time_df.groupby(by='date')['app_rsp_time','byte_count','flow_count','rx_byte_count','rx_flow_count', 'tcp_rsp_time', 'tx_byte_count', 'tx_flow_count','weekday'].max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_12 (LSTM)               (1, 12)                   1008      \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (1, 8)                    104       \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (1, 8)                    0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (1, 6)                    54        \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (1, 6)                    0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (1, 30)                   210       \n",
      "=================================================================\n",
      "Total params: 1,376\n",
      "Trainable params: 1,376\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 31 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      " - 2s - loss: 0.1702 - val_loss: 0.4322\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.1781 - val_loss: 0.4169\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.1779 - val_loss: 0.3961\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.1712 - val_loss: 0.3834\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.1688 - val_loss: 0.3742\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.1687 - val_loss: 0.3649\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.1662 - val_loss: 0.3577\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.1656 - val_loss: 0.3532\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.1661 - val_loss: 0.3503\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.1644 - val_loss: 0.3480\n",
      "MAPE of train =  418.22198528866403\n",
      "rmse of train =  333926.8478989903\n",
      "MAPE of test =  300.3737986112183\n",
      "rmse of test =  285531.82667975227\n"
     ]
    }
   ],
   "source": [
    "dmp,z1,z2,history = lstm_wt_new1(app_rsp_time_df,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "    from matplotlib import pyplot as plt\n",
    "    plt.plot(history.history['loss'])\n",
    "    #plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "    from matplotlib import pyplot as plt\n",
    "    #plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend([ 'test'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A/opt/conda/lib/python3.6/site-packages/pyspark/sql/dataframe.py:138: DeprecationWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  \"Deprecated in 2.0, use createOrReplaceTempView instead.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_13 (LSTM)               (1, 12)                   1008      \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (1, 8)                    104       \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (1, 8)                    0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (1, 6)                    54        \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (1, 6)                    0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (1, 30)                   210       \n",
      "=================================================================\n",
      "Total params: 1,376\n",
      "Trainable params: 1,376\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 23 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      " - 3s - loss: 0.1122 - val_loss: 0.6910\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.1117 - val_loss: 0.6898\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.1106 - val_loss: 0.6896\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.1103 - val_loss: 0.6893\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.1094 - val_loss: 0.6894\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.1098 - val_loss: 0.6886\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.1093 - val_loss: 0.6869\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.1094 - val_loss: 0.6862\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.1089 - val_loss: 0.6863\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.1085 - val_loss: 0.6865\n",
      "MAPE of train =  6.091554810022192\n",
      "rmse of train =  4410.945162169064\n",
      "MAPE of test =  13.585646095847677\n",
      "rmse of test =  13977.795013150266\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_14 (LSTM)               (1, 12)                   1008      \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (1, 8)                    104       \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (1, 8)                    0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (1, 6)                    54        \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (1, 6)                    0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (1, 30)                   210       \n",
      "=================================================================\n",
      "Total params: 1,376\n",
      "Trainable params: 1,376\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 31 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      " - 3s - loss: 0.4151 - val_loss: 3.1128\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.4153 - val_loss: 3.1122\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.4145 - val_loss: 3.1125\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.4142 - val_loss: 3.1143\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.4137 - val_loss: 3.1144\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.4134 - val_loss: 3.1187\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.4134 - val_loss: 3.1206\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.4125 - val_loss: 3.1235\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.4127 - val_loss: 3.1245\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.4116 - val_loss: 3.1291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 20%|██        | 1/5 [01:24<05:38, 84.74s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE of train =  446.50276897205123\n",
      "rmse of train =  34598.57785170945\n",
      "MAPE of test =  128.13461391134618\n",
      "rmse of test =  28354.70130792188\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_15 (LSTM)               (1, 12)                   1008      \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (1, 8)                    104       \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (1, 8)                    0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (1, 6)                    54        \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (1, 6)                    0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (1, 30)                   210       \n",
      "=================================================================\n",
      "Total params: 1,376\n",
      "Trainable params: 1,376\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 23 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      " - 3s - loss: 4.1561 - val_loss: 12.7911\n",
      "Epoch 2/10\n",
      " - 0s - loss: 4.1540 - val_loss: 12.7872\n",
      "Epoch 3/10\n",
      " - 0s - loss: 4.1512 - val_loss: 12.7831\n",
      "Epoch 4/10\n",
      " - 0s - loss: 4.1509 - val_loss: 12.7807\n",
      "Epoch 5/10\n",
      " - 0s - loss: 4.1472 - val_loss: 12.7765\n",
      "Epoch 6/10\n",
      " - 0s - loss: 4.1449 - val_loss: 12.7713\n",
      "Epoch 7/10\n",
      " - 0s - loss: 4.1453 - val_loss: 12.7684\n",
      "Epoch 8/10\n",
      " - 0s - loss: 4.1399 - val_loss: 12.7648\n",
      "Epoch 9/10\n",
      " - 0s - loss: 4.1363 - val_loss: 12.7609\n",
      "Epoch 10/10\n",
      " - 0s - loss: 4.1409 - val_loss: 12.7584\n",
      "MAPE of train =  21.73785449908657\n",
      "rmse of train =  32924.90833527556\n",
      "MAPE of test =  21.044272993866304\n",
      "rmse of test =  4931.455294740769\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_16 (LSTM)               (1, 12)                   1008      \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (1, 8)                    104       \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (1, 8)                    0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (1, 6)                    54        \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (1, 6)                    0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (1, 30)                   210       \n",
      "=================================================================\n",
      "Total params: 1,376\n",
      "Trainable params: 1,376\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 31 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      " - 3s - loss: 0.2919 - val_loss: 0.2583\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.2874 - val_loss: 0.2567\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.2863 - val_loss: 0.2556\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.2844 - val_loss: 0.2542\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.2840 - val_loss: 0.2535\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.2807 - val_loss: 0.2529\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.2865 - val_loss: 0.2519\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.2829 - val_loss: 0.2519\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.2835 - val_loss: 0.2519\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.2816 - val_loss: 0.2512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [02:42<04:08, 82.70s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE of train =  35.62347603940566\n",
      "rmse of train =  29723.55081808268\n",
      "MAPE of test =  141.00023780497028\n",
      "rmse of test =  35031.05404867002\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_17 (LSTM)               (1, 12)                   1008      \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (1, 8)                    104       \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (1, 8)                    0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (1, 6)                    54        \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (1, 6)                    0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (1, 30)                   210       \n",
      "=================================================================\n",
      "Total params: 1,376\n",
      "Trainable params: 1,376\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 23 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      " - 3s - loss: 0.1408 - val_loss: 0.1978\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.1405 - val_loss: 0.1972\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.1397 - val_loss: 0.1966\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.1387 - val_loss: 0.1964\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.1384 - val_loss: 0.1962\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.1368 - val_loss: 0.1961\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.1370 - val_loss: 0.1957\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.1372 - val_loss: 0.1956\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.1353 - val_loss: 0.1954\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.1355 - val_loss: 0.1953\n",
      "MAPE of train =  141.3011262160221\n",
      "rmse of train =  138141.61847145236\n",
      "MAPE of test =  136.5255141937838\n",
      "rmse of test =  210438.8940774568\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_18 (LSTM)               (1, 12)                   1008      \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (1, 8)                    104       \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (1, 8)                    0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (1, 6)                    54        \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (1, 6)                    0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (1, 30)                   210       \n",
      "=================================================================\n",
      "Total params: 1,376\n",
      "Trainable params: 1,376\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 31 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      " - 4s - loss: 0.1709 - val_loss: 0.3877\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.1799 - val_loss: 0.3769\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.1735 - val_loss: 0.3711\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.1708 - val_loss: 0.3685\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.1688 - val_loss: 0.3655\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.1692 - val_loss: 0.3625\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.1679 - val_loss: 0.3607\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.1672 - val_loss: 0.3584\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.1667 - val_loss: 0.3580\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.1674 - val_loss: 0.3569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 60%|██████    | 3/5 [04:02<02:43, 81.83s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE of train =  418.5326289714534\n",
      "rmse of train =  338627.7365029472\n",
      "MAPE of test =  309.5025403696092\n",
      "rmse of test =  283320.68151053396\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_19 (LSTM)               (1, 12)                   1008      \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (1, 8)                    104       \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (1, 8)                    0         \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (1, 6)                    54        \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (1, 6)                    0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (1, 30)                   210       \n",
      "=================================================================\n",
      "Total params: 1,376\n",
      "Trainable params: 1,376\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 23 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      " - 4s - loss: 0.1874 - val_loss: 0.8672\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.1855 - val_loss: 0.8616\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.1857 - val_loss: 0.8543\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.1855 - val_loss: 0.8515\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.1841 - val_loss: 0.8449\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.1848 - val_loss: 0.8427\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.1839 - val_loss: 0.8390\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.1819 - val_loss: 0.8324\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.1817 - val_loss: 0.8270\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.1813 - val_loss: 0.8263\n",
      "MAPE of train =  15.82851142394301\n",
      "rmse of train =  15431.171595263766\n",
      "MAPE of test =  32.13417932389068\n",
      "rmse of test =  31074.886342519527\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_20 (LSTM)               (1, 12)                   1008      \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (1, 8)                    104       \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (1, 8)                    0         \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (1, 6)                    54        \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (1, 6)                    0         \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (1, 30)                   210       \n",
      "=================================================================\n",
      "Total params: 1,376\n",
      "Trainable params: 1,376\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 31 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      " - 4s - loss: 0.1065 - val_loss: 0.5193\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.1063 - val_loss: 0.5194\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.1062 - val_loss: 0.5193\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.1057 - val_loss: 0.5193\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.1054 - val_loss: 0.5200\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.1051 - val_loss: 0.5214\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.1045 - val_loss: 0.5225\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.1049 - val_loss: 0.5223\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.1046 - val_loss: 0.5242\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.1043 - val_loss: 0.5246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 80%|████████  | 4/5 [05:25<01:22, 82.18s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE of train =  28.24883066625929\n",
      "rmse of train =  6428.1498422559935\n",
      "MAPE of test =  35.56421378915831\n",
      "rmse of test =  6846.009282598836\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_21 (LSTM)               (1, 12)                   1008      \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (1, 8)                    104       \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (1, 8)                    0         \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (1, 6)                    54        \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (1, 6)                    0         \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (1, 30)                   210       \n",
      "=================================================================\n",
      "Total params: 1,376\n",
      "Trainable params: 1,376\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 23 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      " - 4s - loss: 0.1554 - val_loss: 0.3644\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.1555 - val_loss: 0.3643\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.1553 - val_loss: 0.3639\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.1551 - val_loss: 0.3631\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.1551 - val_loss: 0.3623\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.1549 - val_loss: 0.3614\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.1547 - val_loss: 0.3599\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.1545 - val_loss: 0.3591\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.1546 - val_loss: 0.3585\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.1542 - val_loss: 0.3579\n",
      "MAPE of train =  9.757076280216133\n",
      "rmse of train =  9506.379532672778\n",
      "MAPE of test =  20.926481089265735\n",
      "rmse of test =  31520.479435847243\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_22 (LSTM)               (1, 12)                   1008      \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (1, 8)                    104       \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (1, 8)                    0         \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (1, 6)                    54        \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (1, 6)                    0         \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (1, 30)                   210       \n",
      "=================================================================\n",
      "Total params: 1,376\n",
      "Trainable params: 1,376\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 31 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      " - 4s - loss: 0.1687 - val_loss: 0.9592\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.1681 - val_loss: 0.9598\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.1672 - val_loss: 0.9625\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.1675 - val_loss: 0.9629\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.1667 - val_loss: 0.9637\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.1659 - val_loss: 0.9654\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.1660 - val_loss: 0.9664\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.1666 - val_loss: 0.9672\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.1666 - val_loss: 0.9669\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.1654 - val_loss: 0.9686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [06:50<00:00, 83.11s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE of train =  49.29945101972192\n",
      "rmse of train =  15883.441140751955\n",
      "MAPE of test =  32.84478792143168\n",
      "rmse of test =  19085.020495998026\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "a = ap_list[0]\n",
    "s = s_list[0]\n",
    "lstm_analysis_df_full = pd.DataFrame()\n",
    "\n",
    "for a in tqdm(ap_list):\n",
    "    for s in s_list:\n",
    "        qt1 = datetime.now()\n",
    "        data = df[(df.application == a ) & (df.source==s)]\n",
    "\n",
    "        df_t = data.registerTempTable('dummy')\n",
    "        df_t = sqlContext.sql('select avg(app_rsp_time) as app_rsp_time, time_stamp, avg(byte_count)  as byte_count, avg(flow_count) as flow_count , avg(rx_byte_count) as rx_byte_count , avg(rx_flow_count) as rx_flow_count , avg(tcp_rsp_time) as tcp_rsp_time , avg(tx_byte_count) as tx_byte_count , avg(tx_flow_count) as tx_flow_count from dummy group by source, application, time_stamp')\n",
    "\n",
    "\n",
    "        # data cleaning\n",
    "        df_t = df_t[df_t.app_rsp_time!=0]\n",
    "        app_rsp_time_df=df_t.toPandas() \n",
    "\n",
    "   \n",
    "        app_rsp_time_df = app_rsp_time_df.sort_values(by='app_rsp_time',ascending=True)       \n",
    "        dates_outlook = pd.to_datetime(pd.Series(app_rsp_time_df.time_stamp),unit='ms')\n",
    "        app_rsp_time_df.index = dates_outlook   \n",
    "        app_rsp_time_df = app_rsp_time_df.sort_values(by='time_stamp')\n",
    "\n",
    "        app_rsp_time_df['date'] = app_rsp_time_df.index.date\n",
    "        del app_rsp_time_df['time_stamp']\n",
    "\n",
    "        app_rsp_time_df = app_rsp_time_df.reset_index()\n",
    "        weekday = app_rsp_time_df.time_stamp.dt.weekday\n",
    "        app_rsp_time_df['weekday'] = weekday\n",
    "        del app_rsp_time_df['time_stamp']\n",
    "\n",
    "        app_rsp_time_df = pd.DataFrame(app_rsp_time_df.groupby(by='date')['app_rsp_time','byte_count','flow_count','rx_byte_count','rx_flow_count', 'tcp_rsp_time', 'tx_byte_count', 'tx_flow_count','weekday'].max())\n",
    "\n",
    "        analyse_df,comare_train,compare_test,history=lstm_wt_new1(app_rsp_time_df,30)\n",
    "        lstm_analysis_df_full = lstm_analysis_df_full.append(analyse_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_rmse</th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>train_mape</th>\n",
       "      <th>test_mape</th>\n",
       "      <th>test_mape_98</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4410.95</td>\n",
       "      <td>13977.80</td>\n",
       "      <td>6.09</td>\n",
       "      <td>13.59</td>\n",
       "      <td>12.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34598.58</td>\n",
       "      <td>28354.70</td>\n",
       "      <td>446.50</td>\n",
       "      <td>128.13</td>\n",
       "      <td>28.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32924.91</td>\n",
       "      <td>4931.46</td>\n",
       "      <td>21.74</td>\n",
       "      <td>21.04</td>\n",
       "      <td>19.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29723.55</td>\n",
       "      <td>35031.05</td>\n",
       "      <td>35.62</td>\n",
       "      <td>141.00</td>\n",
       "      <td>106.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>138141.62</td>\n",
       "      <td>210438.89</td>\n",
       "      <td>141.30</td>\n",
       "      <td>136.53</td>\n",
       "      <td>110.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>338627.74</td>\n",
       "      <td>283320.68</td>\n",
       "      <td>418.53</td>\n",
       "      <td>309.50</td>\n",
       "      <td>272.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15431.17</td>\n",
       "      <td>31074.89</td>\n",
       "      <td>15.83</td>\n",
       "      <td>32.13</td>\n",
       "      <td>31.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6428.15</td>\n",
       "      <td>6846.01</td>\n",
       "      <td>28.25</td>\n",
       "      <td>35.56</td>\n",
       "      <td>28.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9506.38</td>\n",
       "      <td>31520.48</td>\n",
       "      <td>9.76</td>\n",
       "      <td>20.93</td>\n",
       "      <td>19.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15883.44</td>\n",
       "      <td>19085.02</td>\n",
       "      <td>49.30</td>\n",
       "      <td>32.84</td>\n",
       "      <td>17.93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_rmse  test_rmse  train_mape  test_mape  test_mape_98\n",
       "0     4410.95   13977.80        6.09      13.59         12.28\n",
       "0    34598.58   28354.70      446.50     128.13         28.58\n",
       "0    32924.91    4931.46       21.74      21.04         19.86\n",
       "0    29723.55   35031.05       35.62     141.00        106.80\n",
       "0   138141.62  210438.89      141.30     136.53        110.19\n",
       "0   338627.74  283320.68      418.53     309.50        272.69\n",
       "0    15431.17   31074.89       15.83      32.13         31.59\n",
       "0     6428.15    6846.01       28.25      35.56         28.65\n",
       "0     9506.38   31520.48        9.76      20.93         19.96\n",
       "0    15883.44   19085.02       49.30      32.84         17.93"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_analysis_df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>test_mape</th>\n",
       "      <th>std_mape</th>\n",
       "      <th>min_error_rate</th>\n",
       "      <th>max_error_rate</th>\n",
       "      <th>median_error_rate</th>\n",
       "      <th>test_mape_98</th>\n",
       "      <th>total_run_time</th>\n",
       "      <th>application</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DNS</th>\n",
       "      <td>83</td>\n",
       "      <td>14347.067542</td>\n",
       "      <td>9.901298</td>\n",
       "      <td>13.901434</td>\n",
       "      <td>0.001385</td>\n",
       "      <td>0.543710</td>\n",
       "      <td>0.047777</td>\n",
       "      <td>8.122511</td>\n",
       "      <td>0.42</td>\n",
       "      <td>DNS</td>\n",
       "      <td>10.6.1.101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DNS</th>\n",
       "      <td>91</td>\n",
       "      <td>85111.159532</td>\n",
       "      <td>167.166154</td>\n",
       "      <td>251.379000</td>\n",
       "      <td>0.545330</td>\n",
       "      <td>15.012395</td>\n",
       "      <td>1.094283</td>\n",
       "      <td>121.163624</td>\n",
       "      <td>0.38</td>\n",
       "      <td>DNS</td>\n",
       "      <td>134.141.5.104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DHCP</th>\n",
       "      <td>83</td>\n",
       "      <td>4679.961229</td>\n",
       "      <td>19.713460</td>\n",
       "      <td>14.130677</td>\n",
       "      <td>0.004188</td>\n",
       "      <td>0.521598</td>\n",
       "      <td>0.171683</td>\n",
       "      <td>18.415608</td>\n",
       "      <td>0.33</td>\n",
       "      <td>DHCP</td>\n",
       "      <td>10.6.1.101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DHCP</th>\n",
       "      <td>91</td>\n",
       "      <td>35847.273605</td>\n",
       "      <td>213.045084</td>\n",
       "      <td>319.413125</td>\n",
       "      <td>0.143294</td>\n",
       "      <td>18.019294</td>\n",
       "      <td>1.133730</td>\n",
       "      <td>158.255971</td>\n",
       "      <td>0.35</td>\n",
       "      <td>DHCP</td>\n",
       "      <td>134.141.5.104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Radius</th>\n",
       "      <td>83</td>\n",
       "      <td>215411.140954</td>\n",
       "      <td>218.314205</td>\n",
       "      <td>255.396785</td>\n",
       "      <td>0.018991</td>\n",
       "      <td>8.441537</td>\n",
       "      <td>0.811838</td>\n",
       "      <td>193.280626</td>\n",
       "      <td>0.32</td>\n",
       "      <td>Radius</td>\n",
       "      <td>10.6.1.101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Radius</th>\n",
       "      <td>91</td>\n",
       "      <td>297551.948238</td>\n",
       "      <td>453.165254</td>\n",
       "      <td>601.961855</td>\n",
       "      <td>0.007443</td>\n",
       "      <td>20.482787</td>\n",
       "      <td>1.646370</td>\n",
       "      <td>398.161342</td>\n",
       "      <td>0.33</td>\n",
       "      <td>Radius</td>\n",
       "      <td>134.141.5.104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LDAP</th>\n",
       "      <td>83</td>\n",
       "      <td>17253.779140</td>\n",
       "      <td>19.043158</td>\n",
       "      <td>12.934330</td>\n",
       "      <td>0.010976</td>\n",
       "      <td>0.571972</td>\n",
       "      <td>0.153255</td>\n",
       "      <td>17.516996</td>\n",
       "      <td>0.33</td>\n",
       "      <td>LDAP</td>\n",
       "      <td>10.6.1.101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LDAP</th>\n",
       "      <td>91</td>\n",
       "      <td>3542.271013</td>\n",
       "      <td>16.693480</td>\n",
       "      <td>30.160869</td>\n",
       "      <td>0.004622</td>\n",
       "      <td>1.764835</td>\n",
       "      <td>0.115175</td>\n",
       "      <td>11.183479</td>\n",
       "      <td>0.33</td>\n",
       "      <td>LDAP</td>\n",
       "      <td>134.141.5.104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kerberos</th>\n",
       "      <td>83</td>\n",
       "      <td>31921.432920</td>\n",
       "      <td>21.677883</td>\n",
       "      <td>15.451168</td>\n",
       "      <td>0.007299</td>\n",
       "      <td>0.501217</td>\n",
       "      <td>0.151835</td>\n",
       "      <td>20.540130</td>\n",
       "      <td>0.33</td>\n",
       "      <td>Kerberos</td>\n",
       "      <td>10.6.1.101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kerberos</th>\n",
       "      <td>91</td>\n",
       "      <td>47893.965102</td>\n",
       "      <td>82.133054</td>\n",
       "      <td>42.150376</td>\n",
       "      <td>0.263044</td>\n",
       "      <td>2.754134</td>\n",
       "      <td>0.811270</td>\n",
       "      <td>75.468215</td>\n",
       "      <td>0.33</td>\n",
       "      <td>Kerberos</td>\n",
       "      <td>134.141.5.104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          length      test_rmse   test_mape    std_mape  min_error_rate  \\\n",
       "DNS           83   14347.067542    9.901298   13.901434        0.001385   \n",
       "DNS           91   85111.159532  167.166154  251.379000        0.545330   \n",
       "DHCP          83    4679.961229   19.713460   14.130677        0.004188   \n",
       "DHCP          91   35847.273605  213.045084  319.413125        0.143294   \n",
       "Radius        83  215411.140954  218.314205  255.396785        0.018991   \n",
       "Radius        91  297551.948238  453.165254  601.961855        0.007443   \n",
       "LDAP          83   17253.779140   19.043158   12.934330        0.010976   \n",
       "LDAP          91    3542.271013   16.693480   30.160869        0.004622   \n",
       "Kerberos      83   31921.432920   21.677883   15.451168        0.007299   \n",
       "Kerberos      91   47893.965102   82.133054   42.150376        0.263044   \n",
       "\n",
       "          max_error_rate  median_error_rate  test_mape_98  total_run_time  \\\n",
       "DNS             0.543710           0.047777      8.122511            0.42   \n",
       "DNS            15.012395           1.094283    121.163624            0.38   \n",
       "DHCP            0.521598           0.171683     18.415608            0.33   \n",
       "DHCP           18.019294           1.133730    158.255971            0.35   \n",
       "Radius          8.441537           0.811838    193.280626            0.32   \n",
       "Radius         20.482787           1.646370    398.161342            0.33   \n",
       "LDAP            0.571972           0.153255     17.516996            0.33   \n",
       "LDAP            1.764835           0.115175     11.183479            0.33   \n",
       "Kerberos        0.501217           0.151835     20.540130            0.33   \n",
       "Kerberos        2.754134           0.811270     75.468215            0.33   \n",
       "\n",
       "         application         source  \n",
       "DNS              DNS     10.6.1.101  \n",
       "DNS              DNS  134.141.5.104  \n",
       "DHCP            DHCP     10.6.1.101  \n",
       "DHCP            DHCP  134.141.5.104  \n",
       "Radius        Radius     10.6.1.101  \n",
       "Radius        Radius  134.141.5.104  \n",
       "LDAP            LDAP     10.6.1.101  \n",
       "LDAP            LDAP  134.141.5.104  \n",
       "Kerberos    Kerberos     10.6.1.101  \n",
       "Kerberos    Kerberos  134.141.5.104  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prophet_analysis_df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>test_mape</th>\n",
       "      <th>test_mape_98</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xgboost_hist5_forcast_30</td>\n",
       "      <td>15.36</td>\n",
       "      <td>13.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xgboost_hist5_forcast_30</td>\n",
       "      <td>38.11</td>\n",
       "      <td>36.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xgboost_hist5_forcast_30</td>\n",
       "      <td>22.35</td>\n",
       "      <td>21.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xgboost_hist5_forcast_30</td>\n",
       "      <td>84.55</td>\n",
       "      <td>63.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xgboost_hist5_forcast_30</td>\n",
       "      <td>134.86</td>\n",
       "      <td>111.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xgboost_hist5_forcast_30</td>\n",
       "      <td>115.08</td>\n",
       "      <td>100.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xgboost_hist5_forcast_30</td>\n",
       "      <td>29.60</td>\n",
       "      <td>28.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xgboost_hist5_forcast_30</td>\n",
       "      <td>22.08</td>\n",
       "      <td>20.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xgboost_hist5_forcast_30</td>\n",
       "      <td>29.47</td>\n",
       "      <td>28.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xgboost_hist5_forcast_30</td>\n",
       "      <td>29.98</td>\n",
       "      <td>28.21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model  test_mape  test_mape_98\n",
       "0  xgboost_hist5_forcast_30      15.36         13.70\n",
       "0  xgboost_hist5_forcast_30      38.11         36.09\n",
       "0  xgboost_hist5_forcast_30      22.35         21.02\n",
       "0  xgboost_hist5_forcast_30      84.55         63.81\n",
       "0  xgboost_hist5_forcast_30     134.86        111.73\n",
       "0  xgboost_hist5_forcast_30     115.08        100.54\n",
       "0  xgboost_hist5_forcast_30      29.60         28.82\n",
       "0  xgboost_hist5_forcast_30      22.08         20.85\n",
       "0  xgboost_hist5_forcast_30      29.47         28.73\n",
       "0  xgboost_hist5_forcast_30      29.98         28.21"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_analysis_df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34.2, 29.79, 51.9054682216334)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_analysis_df_full.test_mape.quantile(.5) ,xgb_analysis_df_full.test_mape.quantile(.5),prophet_analysis_df_full.test_mape.quantile(.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
